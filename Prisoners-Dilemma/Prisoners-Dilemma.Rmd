---
# IMPORTANT: Change settings here, but DO NOT change the spacing.
# Remove comments and add values where applicable.
# The descriptions below should be self-explanatory

title: "Beyond Tit for Tat: A Deep Dive into Strategy and Social Preferences"
#subtitle: "This will appear as Right Header"

documentclass: "elsarticle"

# --------- Thesis title (Optional - set to FALSE by default).
# You can move the details below around as you please.
Thesis_FP: FALSE
# Entry1: "An unbelievable study with a title spanning multiple lines."
# Entry2: "\\textbf{Some Guy}" # textbf for bold
# Entry3: "A thesis submitted toward the degree of Doctor of Philosophy"
# Uni_Logo: Tex/Logo.png # Place a logo in the indicated location (from your root, e.g. defaults to ~/Tex/Logo.png) and uncomment this line. Leave uncommented for no image
# Logo_width: 0.3 # If using a logo - use this to set width (size) of image
# Entry4: "Under the supervision of: \\vfill Prof. Joe Smith and Dr. Frank Smith"
# Entry5: "Stellenbosch University"
# Entry6: April 2020
# Entry7:
# Entry8:

# --------- Front Page
# Comment: ----- Follow this pattern for up to 5 authors
AddTitle: TRUE # Use FALSE when submitting to peer reviewed platform. This will remove author names.
Author1: "Liam Andrew Beattie"  # First Author - note the thanks message displayed as an italic footnote of first page.
Ref1: "Microeconomics 871, Stellenbosch University, South Africa" # First Author's Affiliation
Email1: "22562435\\@sun.ac.za" # First Author's Email address

Author2: "Abdul Qaadir Cassiem"
#Ref2: "Some other Institution, Cape Town, South Africa"
Email2: "20863667\\@sun.ac.za"
CommonAffiliation_12: TRUE # If Author 1 and 2 have a common affiliation. Works with _13, _23, etc.

# Author3: "John Doe"
# Email3: "Joe\\@gmail.com"

#CorrespAuthor_1: TRUE  # If corresponding author is author 3, e.g., use CorrespAuthor_3: TRUE

# Comment out below to remove both. JEL Codes only given if keywords also given.
# keywords: "Multivariate GARCH \\sep Kalman Filter \\sep Copula" # Use \\sep to separate
# JELCodes: "L250 \\sep L100"

# ----- Manage headers and footers:
#BottomLFooter: $Title$
#BottomCFooter:
#TopLHeader: \leftmark # Adds section name at topleft. Remove comment to add it.
BottomRFooter: "\\footnotesize Page \\thepage" # Add a '#' before this line to remove footer.
addtoprule: TRUE
addfootrule: TRUE               # Use if footers added. Add '#' to remove line.

# --------- page margins:
margin: 2.3 # Sides
bottom: 2 # bottom
top: 2.5 # Top
HardSet_layout: TRUE # Hard-set the spacing of words in your document. This will stop LaTeX squashing text to fit on pages, e.g.
# This is done by hard-setting the spacing dimensions. Set to FALSE if you want LaTeX to optimize this for your paper.

# --------- Line numbers
linenumbers: FALSE # Used when submitting to journal

# ---------- References settings:
# You can download cls format here: https://www.zotero.org/ - simply search for your institution. You can also edit and save cls formats here: https://editor.citationstyles.org/about/
# Hit download, store it in Tex/ folder, and change reference below - easy.
bibliography: Tex/ref.bib       # Do not edit: Keep this naming convention and location.
csl: Tex/harvard-stellenbosch-university.csl # referencing format used.
# By default, the bibliography only displays the cited references. If you want to change this, you can comment out one of the following:
#nocite: '@*' # Add all items in bibliography, whether cited or not
# nocite: |  # add specific references that aren't cited
#  @grinold2000
#  @Someoneelse2010

# ---------- General:
RemovePreprintSubmittedTo: TRUE  # Removes the 'preprint submitted to...' at bottom of titlepage
Journal: "Journal of Finance"   # Journal that the paper will be submitting to, if RemovePreprintSubmittedTo is set to TRUE.
toc: FALSE                       # Add a table of contents
numbersections: TRUE             # Should sections (and thus figures and tables) be numbered?
fontsize: 11pt                  # Set fontsize
linestretch: 1.2                # Set distance between lines.
link-citations: FALSE            # This creates dynamic links to the papers in reference list.

### Adding additional latex packages:
# header-includes:
#    - \usepackage{colortbl} # Add additional packages here.

output:
  pdf_document:
    latex_engine: pdflatex
    keep_tex: TRUE
    template: Tex/TexDefault.txt
    fig_width: 3.5  # Adjust default figure sizes. This can also be done in the chunks of the text.
    fig_height: 3.5
header-includes:
  - \usepackage{lscape}

---

<!-- First: Set your default preferences for chunk options: -->

<!-- If you want a chunk's code to be printed, set echo = TRUE. message = FALSE stops R printing ugly package loading details in your final paper too. I also suggest setting warning = FALSE and checking for warnings in R, else you might find ugly warnings in your paper. -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 6, fig.height = 5, fig.pos="H", fig.pos = 'H')
# Note: Include = FALSE implies the code is executed, but not printed in your pdf.
# warning and message = FALSE implies ugly messages and warnings are removed from your pdf.
# These should be picked up when you execute the command chunks (code sections below) in your rmd, not printed in your paper!

# Lets load in example data, and see how this can be stored and later called from your 'data' folder.
load('data/fulldata.RData')
if(!require("tidyverse")) install.packages("tidyverse")
library(tidyverse)
library(knitr)
library(kableExtra)
map(paste0("code/", list.files("code/", "*.R$")), source)  # source all your R scripts


```



<!-- ############################## -->
<!-- # Start Writing here: -->
<!-- ############################## -->

# Introduction \label{Introduction}

The phrase horses for courses alludes to the fact that a racehorse performs best on a racecourse to which it is specifically suited. More generally this idiom is used to express that certain tools and strategies are better suited over others depending on the task or situations at hand. In the context of the repeated prisoners' dilemma, the strategy of Tit for Tat (TfT), where one mimics their opponent's previous move, reigns supreme and is best suited over others for the situation at hand.

This paper investigates strategic behaviour in the repeated Prisoner's Dilemma by conducting a tournament inspired by @axelrod1980effective but expands the original framework by including distinct strategies. These strategies, categorized into cooperative, defecting, random, and adaptive types, play against each other in 200 rounds of the Prisoner’s Dilemma, allowing for a comprehensive evaluation of their performance. By considering both standard scenarios and environments with varying levels of social preferences, this study explores how different strategies fare in diverse settings, particularly focusing on the adaptability and effectiveness of Tit for Tat (TfT) variants, which have historically been prominent in such tournaments.

Consider a standard prisoners’ dilemma pay-off table:


```{=latex}
\begin{table}[ht]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Player 1 / Player 2} & \textbf{C (Cooperate)} & \textbf{D (Defect)} \\
\hline
\textbf{C (Cooperate)} & $(R, R)$ & $(S, T)$ \\
\hline
\textbf{D (Defect)} & $(T, S)$ & $(P, P)$ \\
\hline
\end{tabular}
\caption{Prisoner's Dilemma Payoff Matrix with $R$, $P$, $S$, and $T$ Outcomes}
\end{table}

```

Adjusting the values of R (Reward for mutual cooperation), P (Punishment for mutual defection), S (Sucker’s pay-off for cooperating while the other defects), and T (Temptation to defect when the other cooperates) is an example of within game pay-off adjustments. These adjustments might produce a new dominant strategy and our analysis aims to find if it does.

From-game adjustments are a bit different and it considers the utility a player gets from the payoffs of its opponent. 

```{=latex}
\begin{table}[ht]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Player 1 / Player 2} & \textbf{C (Cooperate)} & \textbf{D (Defect)} \\
\hline
\textbf{C (Cooperate)} & $(R(1-p) + Rp,     R(1-p) + Rp)$ & $(S(1-p) + Tp,     T(1-p)+Sp)$ \\
\hline
\textbf{D (Defect)} & $(T(1-p) + Sp,    S(1-p) + Tp)$ & $(P(1-p) + Pp,     P(1-p) + P)$ \\
\hline
\end{tabular}
\caption{Prisoner's Dilemma Payoff Matrix}
\end{table}
```


The level _p_ here is adapted from @charness2002understanding who created a utility function that captures various social preferences. In essence, _p_ is how much you care about your opponent's pay-offs as well as your own. In standard prisoners’ dilemma games, this is 0 and thus people are purely self-interested. If we let our pay-offs be R = 3, T = 5, S = 0, and P = 3, then this situation in strategic form would look like:

```{=latex}
\begin{table}[ht]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Player 1 / Player 2} & \textbf{C (Cooperate)} & \textbf{D (Defect)} \\
\hline
\textbf{C (Cooperate)} & $(3, 3)$ & $(0, 5)$ \\
\hline
\textbf{D (Defect)} & $(5, 0)$ & $(1, 1)$ \\
\hline
\end{tabular}
\caption{Prisoner's Dilemma Payoff Matrix for $p = 0$ (Self-interested person)}
\end{table}
```


However we can adjust the value of _p_ for people who are partially considerate of other people's outcomes, or we can make people egalitarian who care just as much for others as they do for themselves.

```{=latex}
\begin{table}[ht]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Player 1 / Player 2} & \textbf{C (Cooperate)} & \textbf{D (Defect)} \\
\hline
\textbf{C (Cooperate)} & $(3, 3)$ & $(1, 4)$ \\
\hline
\textbf{D (Defect)} & $(4, 1)$ & $(1, 1)$ \\
\hline
\end{tabular}
\caption{Prisoner's Dilemma Payoff Matrix for $p = 0.2$ (Partially considers others' outcomes)}
\end{table}
```


```{=latex}
\begin{table}[ht]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Player 1 / Player 2} & \textbf{C (Cooperate)} & \textbf{D (Defect)} \\
\hline
\textbf{C (Cooperate)} & $(3, 3)$ & $(2.5, 2.5)$ \\
\hline
\textbf{D (Defect)} & $(2.5, 2.5)$ & $(1, 1)$ \\
\hline
\end{tabular}
\caption{Prisoner's Dilemma Payoff Matrix for $p = 0.5$ (Egalitarian person)}
\end{table}
```


_p_ could also take a negative value, which indicates a person is status-seeking and actively wants to bring down their opponent. 

```{=latex}
\begin{table}[ht]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Player 1 / Player 2} & \textbf{C (Cooperate)} & \textbf{D (Defect)} \\
\hline
\textbf{C (Cooperate)} & $(3.6, 3.6)$ & $(-1, 6)$ \\
\hline
\textbf{D (Defect)} & $(6, -1)$ & $(0.8, 0.8)$ \\
\hline
\end{tabular}
\caption{Prisoner's Dilemma Payoff Matrix for $p = -0.2$ (Negative influence by others' outcomes)}
\end{table}
```


It would be interesting to see under which values of _p_ the dominant strategy changes.



# Literature Review\label{litreview}

The exploration of strategy choices within the framework of the prisoner’s dilemma has garnered extensive attention in recent literature. @axelrod1980effective foundational work emphasized effective strategies in iterated scenarios, sparking a wealth of research on strategic behaviour in repeated interactions. His tournament studies laid the groundwork for understanding how cooperation can emerge in repeated prisoner’s dilemmas through strategies like Tit for Tat (TfT) and other forms of reciprocity. This exploration of cooperative behaviour in an inherently competitive framework has been expanded by various scholars, each contributing unique insights into how individuals and institutions behave when faced with the tension between cooperation and defection.

Recent studies, such as that by @dalbo2019strategy, have focused on the strategic complexity observed in infinitely repeated games. They provide empirical evidence that players in these settings are highly adaptive, often switching strategies depending on the payoffs and the perceived actions of their opponents. In contrast, @breitmoser2015cooperation questions the reciprocity-based models that dominate much of the literature, suggesting that while cooperation is often observed, it may not always stem from reciprocal motivations. @breitmoser2015cooperation finds that in many cases, cooperation might emerge from individual incentives structured by the game's dynamics, rather than a direct desire to reciprocate.

A significant portion of the literature has also addressed the challenges of finite versus infinite iterations of the dilemma. @kreps1982rational introduced the idea that even in finitely repeated games, players may behave as though they are in an infinite game, cooperating for fear of future retaliation, despite the known endpoint. This idea challenges the strict predictions of defection in the final stages of finitely repeated games and has been explored further by @embrey2017cooperation, who conducted laboratory experiments to observe how players adapt their strategies in finite games. Their findings support the hypothesis that cooperation can persist under certain conditions, even in games with a clear end.

Adding to the complexity of the strategic decision-making landscape, @romero2018constructing investigated the cognitive processes behind strategy construction in indefinite games, emphasizing how players use heuristics and simplified mental models to navigate the uncertainty of the game's length. This aligns with @farrell1988evolutionary earlier work on evolutionary stability, where they explored how long-term strategies evolve to withstand deviations from equilibrium behaviours.
From a computational perspective, @garcia2018no utilized simulations to demonstrate that no single strategy could consistently dominate in the repeated prisoner’s dilemma, suggesting that adaptability and context-dependent strategy selection are key to success in such settings. Similarly, @gaudesi2016exploiting leveraged evolutionary modelling techniques to demonstrate how strategies evolve over time, competing in a dynamic landscape shaped by both cooperation and competition.
The link between theoretical models and real-world application has also been a point of focus. @lange2007teaching developed computerized tournaments to teach the mechanics of the repeated prisoner’s dilemma, blending theory with practice and providing insights into how strategic choices might play out in educational settings. Such studies highlight the importance of teaching and learning mechanisms in understanding strategic behaviour in social dilemmas. Taken together, the contemporary literature on strategy selection in the prisoner’s dilemma underscores the complexity of human decision-making in repeated interactions. 

# Game Construction
## The Basic Repeated Prisoners dilemma 

This paper conducts a tournament modelled after @axelrod1980effective but incorporates a wider array of strategies. A total of 25 strategies are used in this repeated Prisoner’s Dilemma tournament. These strategies are categorized in Table 3.1 according to their types. Some strategies always cooperate or always defect, while others, called random strategies, cooperate with a set probability. For example, Random 90% cooperates 90% of the time and defects 10% of the time. Strategies extracted from the literature are marked with references in brackets next to their names. Those without references are new strategies introduced in this paper, each of which will be explained in detail.

```{=latex}
\renewcommand{\arraystretch}{1.2} % Adjust row spacing
\begin{table}[ht]
\centering
\tiny % Reduces font size for compactness
\begin{tabular}{|>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{2cm}|>{\centering\arraybackslash}p{2cm}|}
\hline
\textbf{Always Strategies} & \textbf{Tit for Tat Variants} & \textbf{Win-Stay/ Lose-Switch} & \textbf{Punishment-Based} & \textbf{Adaptive/ Adjusting} & \textbf{Gradient/ Probability-Based} & \textbf{Random Strategies} \\
\hline
Always Cooperate & Tit for Tat & Pavlov & Grim Trigger & Adaptive Defector & Progressive Cooperator & Random 10\% \\
Always Defect & Tit for Two Tats & & Bully & Adaptive Peacekeeper & Diminishing Cooperator & Random 25\% \\
& Tit for Tat with Randomisation & & Retaliatory Defector & Probing Adjuster & Bounded Gradient & Random 50\% \\
& Tit for Tat with Forgiveness & & & Forgiving Tester & Recent Gradient & Random 75\% \\
& & & & Prober & & Random 90\% \\
& & & & Cautious Rebuilder & & \\
\hline
\end{tabular}
\caption{Categorisation of Strategy Types Used in the Prisoner's Dilemma Tournament}
\end{table}


```

One such strategy is Retaliatory Defector. It begins by cooperating but defects for two rounds if its opponent defects. After two rounds, if the opponent resumes cooperation, Retaliatory Defector will also return to cooperating. Another strategy, Adaptive Defector, also starts by cooperating, but thereafter assesses the opponent’s behaviour over the last five rounds. If the opponent has defected more than 40% of the time, Adaptive Defector will defect; otherwise, it continues to cooperate.
Adaptive Peacekeeper focuses on maintaining cooperation while testing the opponent’s behaviour periodically. It starts by cooperating but defects every sixth round to probe the opponent's reaction. If the opponent defects more than twice consecutively after these probes, Adaptive Peacekeeper responds with defection. However, if both players defected in the previous round, the strategy returns to cooperation, signalling a willingness to restore collaboration.

Probing Adjuster is another adaptive strategy. It begins by cooperating but alters its behaviour based on the opponent's past actions. If the opponent defects three times in a row, Probing Adjuster responds by defecting as well. However, if both players defected in the previous round, it tries to re-establish cooperation by cooperating again. If the opponent cooperates after the player defects, the player will continue defecting, exploiting the opponent's leniency. Additionally, if the player cooperates while the opponent cooperates, the player switches to defection to test the opponent’s reaction to a shift in strategy.

Prober tests the opponent’s resilience to defection by defecting for three consecutive rounds if the opponent defects. It always begins with cooperation, but when an opponent defects, Prober immediately retaliates with three rounds of defection before returning to cooperation. This approach aims to probe the opponent's willingness to adjust their behaviour in response to repeated defection, while maintaining a cooperative default when unprovoked.

Forgiving Tester emphasizes cooperation but incorporates occasional defections to gauge the opponent's response. It begins by cooperating, but every fourth round it defects. If the opponent defects three times in a row, Forgiving Tester will retaliate by continuing to defect until the opponent cooperates again. However, if the opponent cooperates after a test defection, or if both players defect in the same round, Forgiving Tester quickly forgives and returns to cooperation. This strategy encourages long-term collaboration while punishing consistent defections.

Cautious Rebuilder starts by cooperating and follows three rules in its decision-making. First, if the opponent defects three times in a row, Cautious Rebuilder will defect until the opponent cooperates again. Second, if the opponent's last move was a defection but the opponent has not defected three times consecutively, Cautious Rebuilder will cooperate, trying to repair relations. Third, after every five rounds, it will defect once to test the opponent’s tolerance for defection.
In line with @axelrod1980effective, each strategy plays against itself and every other strategy once in the tournament. Each game consists of 200 rounds of the repeated Prisoner’s Dilemma, and the payoffs and outcomes are recorded for every round. The strategy that accumulates the most points after 200 rounds wins the individual game. The overall winner of the tournament is the strategy that achieves the highest total points across all games. The standard Prisoners Dilemma from @axelrod1980effective will be played and is given in the table below:

```{=latex}
\begin{table}[ht]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Player 1 / Player 2} & \textbf{C (Cooperate)} & \textbf{D (Defect)} \\
\hline
\textbf{C (Cooperate)} & $(3, 3)$ & $(0, 5)$ \\
\hline
\textbf{D (Defect)} & $(5, 0)$ & $(1, 1)$ \\
\hline
\end{tabular}
\caption{Prisoner's Dilemma Payoff Matrix}
\end{table}
```

## The Repeated Prisoners Dilemma With Social Preferences  

This game is played exactly the same as above except now Social Preferences are taken into account. From-game adjustments are a bit different and it considers the utility a player gets from the payoffs of its opponent. The standard Prisoners Dilemma payoff Matrix with from-game adjustments is given below:

```{=latex}
\begin{table}[ht]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Player 1 / Player 2} & \textbf{C (Cooperate)} & \textbf{D (Defect)} \\
\hline
\textbf{C (Cooperate)} & $(3(1-p) + 3p,     3(1-p) + 3p)$ & $(0(1-p) + 5p,     5(1-p)+0p)$ \\
\hline
\textbf{D (Defect)} & $(5(1-p) + 0p,    0(1-p) + 5p)$ & $((1-p) + p,     (1-p) + p)$ \\
\hline
\end{tabular}
\caption{Prisoner's Dilemma Payoff Matrix}
\end{table}
```

The level _p_ here is adapted from @charness2002understanding who created a utility function that captures various social preferences. In essence, _p_ is how much you care about your opponent's pay-offs as well as your own. This paper will conduct the tournament as above for a range of _p_ values starting from _p_ = -1 where individuals are status seeking to _p_ = 0.5 where indivduals care half as much about themselves as the do about others



```{r}
strategies <- list(
    'Always Cooperate' = always_cooperate,
    'Always Defect' = always_defect,
    'Tit for Tat' = tit_for_tat,
    'Tit for Two Tats' = tit_for_two_tats,
    'Tit for Tat with Forgiveness' = tit_for_tat_forgiveness,
    'Tit for Tat with Randomisation' = tit_for_tat_randomisation,
    Pavlov = pavlov,
    'Grim/Trigger' = grim_trigger,
    Bully = bully,
    'Retaliatory Defector' = retaliatory_defector,
    
    'Adaptive Defector' = adaptive_defector,
    'Adaptive Peacekeep' = adaptive_peacekeeper,
    'Probing Adjuster' = probing_adjuster,
    'Forgiving Tester' = forgiving_tester,
    Prober = prober,
    'Cautious Rebuilder' = cautious_rebuilder,
    
    'Progressive Cooperator' = gradual_adjustment_strategy_inc_200,
    'Deminishing Cooperator' = gradual_adjustment_strategy_dec_200,
    'Bounded Gradient' = bounded_random_strategy,
    'Recent Gradient' = gradient_cooperation,
    
    
    'Random 10%' = random_0.1,
    'Random 25%' = random_0.25,
    'Random 50%' = random_0.5,
    'Random 75%' = random_0.75,
    'Random 90%' = random_0.9
    

)
```




```{r}
#Abdul you can ignore this, this is just how the final data was created. It took a few hours to run

# system.time({
# set.seed(100)
# p_0_results <- tournament_payoff_df(strategies,rounds = 200)
# set.seed(100)
# fullresults_rank<- ranking_matrix_for_sequence_p(strategies, rounds = 200, rank = TRUE)
# set.seed(100)
# fullresults_total<- ranking_matrix_for_sequence_p(strategies, rounds = 200, rank = FALSE)
# #save.image(file='data/fulldata.RData')
# 
# })
```




















# Game Results
## The Standard Prisoners Dilemma Tournament
 
After the conclusion of the tournament, most interestingly unlike @axelrod1980effective, this paper does not find Tft as the winner in the standard Repeated Prisoners Dilemma. Table 4.1 gives the standard tournament without social preferences. The winner of the tournament was Probing Adjuster with 13575 points followed by Tft with Randomization which had 12887 points and Bully coming in third with 12869 points. In this game Tft came fourth which leads us to believe similarly to @axelrod1980effective that Tft may have won due to the other strategies in the tournament. The winner of the Prisoners Dilemma is highly dependent on the strategies in the tournament.
Always Cooperate and Random 90% came in second last and last respectively. This is as expected as the tournament included strategies that took advantage of other strategies which always cooperated. Most interestingly, if the adaptive strategies are removed then the Grim/Trigger strategy would have won the game. Also, even though Probing Adjuster won the tournament, the group of adaptive strategies as a whole performed worse than the group of Tit for Tat variant strategies. This result shows the robustness of Tit for Tat variants to perform well against both cooperators and defectors, maintaining high scores overall.

\newpage

\begin{landscape}


\vfill
```{r}


library(kableExtra)
create_tournament_table(p_0_results, p_value = 0)


```

\vfill

\end{landscape}



## The Prisoners Dilemma Tournament with Social Preferences

Table 4.2 gives the standings of the tournament across different social preferences. The rankings of strategies change across these different values of _p_, illustrating how varying degrees of altruism or hostility affect the success of each strategy. Notably Always Cooperate improves its ranking as _p_ increases, moving from 25th at _p_ = -0.1 to 1st when _p_ = 0.45, showing that cooperative strategies perform better in environments where mutual benefit is prioritized. Always Defect, conversely, declines in rank as _p_ increases, indicating that purely selfish strategies are less effective when players care about the well-being of others. Tit for Tat maintains a relatively stable performance across various _p_ values, reflecting its robustness as a strategy that adapts well to different social preferences. This holds true for the TfT variations in general. Probing Adjuster, which ranked first when _p_ = -0.1, drops significantly as p increases, indicating that more complex strategies designed for selfish environments are less effective in altruistic settings.
 







```{r}
fullresults_rank %>% format_table()
```



Figure \ref{pvalues} presents a graphical representation of how the total points of different strategies change as p varies. The x-axis represents different _p_ values, while the y-axis shows the total points for each strategy. From the figure we observe that Always Cooperate shows a steady increase in total points as _p_ increases, reinforcing the observation that this strategy benefits from environments where players value mutual cooperation. Always Defect exhibits declining points as _p_ increases, suggesting that as social preferences rise, defectors are penalized for their selfishness. TfT maintains consistently high points across all _p_ values, further proving its adaptability and effectiveness in both selfish and cooperative environments. Strategies like Probing Adjuster and Bully, which perform well in self-interested settings, see their points drop as _p_ increases, emphasizing their reduced effectiveness in more cooperative contexts.




```{r, fig.cap="Strategies' Total Utilities for Different Strategies Accross p\\label{pvalues}", fig.height = 6,fig.align='center'}

fullresults_total %>%   plot_total_utilities()

```

Figure \ref{pvalues} presents a graphical representation of how the total points of different strategies change as p varies. The x-axis represents different _p_ values, while the y-axis shows the total points for each strategy. From the figure we observe that Always Cooperate shows a steady increase in total points as _p_ increases, reinforcing the observation that this strategy benefits from environments where players value mutual cooperation. Always Defect exhibits declining points as _p_ increases, suggesting that as social preferences rise, defectors are penalized for their selfishness. TfT maintains consistently high points across all _p_ values, further proving its adaptability and effectiveness in both selfish and cooperative environments. Strategies like Probing Adjuster and Bully, which perform well in self-interested settings, see their points drop as _p_ increases, emphasizing their reduced effectiveness in more cooperative contexts.

```{r}
fullresults_total %>% create_ranking_table()
```

The analysis of the tournament shows how different strategies perform in the Prisoner's Dilemma under varying levels of social preference. The findings yield that in selfish scenarios, probing and aggressive strategies tend to win but as altruism increases, these strategies struggle. TfT variant strategies have shown to be robust under varying social preferences as can be seen in Table 4.3. Tft has the highest average points across the differing p-values showing its robustness in the face of differing social preferences. These findings once again provide insight into the strength of the TfT strategy. In Prisoners Dilemma games where preferences may be hidden, TfT would according to these findings perform the best.  

```{r}

fullresults_total %>% format_table( title = "Strategy Values Across Different p Values")
```

# Conclusion

The tournament results reveal that strategic success in the Prisoner’s Dilemma is highly dependent on the composition of competing strategies and the level of social preferences. Probing Adjuster outperformed other strategies in the standard setting, but TfT and its variants demonstrated remarkable robustness across different social preference levels. As altruism increases, cooperative strategies gain prominence, while aggressive strategies struggle. The findings highlight the continued relevance of TfT, particularly in contexts where social preferences or hidden intentions influence decision-making, offering valuable insights into strategic adaptability in competitive environments.

\newpage
# References


